{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T23:02:27.080964Z","iopub.status.busy":"2024-07-28T23:02:27.080137Z","iopub.status.idle":"2024-07-28T23:02:42.634914Z","shell.execute_reply":"2024-07-28T23:02:42.633874Z","shell.execute_reply.started":"2024-07-28T23:02:27.080931Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in d:\\anaconda\\envs\\arten\\lib\\site-packages (2.19.1)\n","Requirement already satisfied: evaluate in d:\\anaconda\\envs\\arten\\lib\\site-packages (0.4.2)\n","Requirement already satisfied: jiwer in d:\\anaconda\\envs\\arten\\lib\\site-packages (3.0.4)\n","Requirement already satisfied: huggingface_hub in d:\\anaconda\\envs\\arten\\lib\\site-packages (0.23.1)\n","Requirement already satisfied: filelock in d:\\anaconda\\envs\\arten\\lib\\site-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from datasets) (1.24.3)\n","Requirement already satisfied: pyarrow>=12.0.0 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from datasets) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in d:\\anaconda\\envs\\arten\\lib\\site-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from datasets) (4.66.4)\n","Requirement already satisfied: xxhash in d:\\anaconda\\envs\\arten\\lib\\site-packages (from datasets) (1.4.4)\n","Requirement already satisfied: multiprocess in d:\\anaconda\\envs\\arten\\lib\\site-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\n","Requirement already satisfied: aiohttp in d:\\anaconda\\envs\\arten\\lib\\site-packages (from datasets) (3.9.5)\n","Requirement already satisfied: packaging in d:\\anaconda\\envs\\arten\\lib\\site-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from jiwer) (8.1.7)\n","Requirement already satisfied: rapidfuzz<4,>=3 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from jiwer) (3.9.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from huggingface_hub) (4.12.2)\n","Requirement already satisfied: colorama in d:\\anaconda\\envs\\arten\\lib\\site-packages (from click<9.0.0,>=8.1.3->jiwer) (0.4.6)\n","Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from requests>=2.19.0->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from requests>=2.19.0->datasets) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.7.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from pandas->datasets) (2.9.0)\n","Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install datasets evaluate jiwer huggingface_hub ipywidgets\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ipywidgets in d:\\anaconda\\envs\\arten\\lib\\site-packages (8.1.3)\n","Requirement already satisfied: comm>=0.1.3 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipywidgets) (0.2.2)\n","Requirement already satisfied: ipython>=6.1.0 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipywidgets) (8.12.2)\n","Requirement already satisfied: traitlets>=4.3.1 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipywidgets) (5.14.3)\n","Requirement already satisfied: widgetsnbextension~=4.0.11 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipywidgets) (4.0.11)\n","Requirement already satisfied: jupyterlab-widgets~=3.0.11 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipywidgets) (3.0.11)\n","Requirement already satisfied: backcall in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n","Requirement already satisfied: decorator in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n","Requirement already satisfied: matplotlib-inline in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n","Requirement already satisfied: pickleshare in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n","Requirement already satisfied: pygments>=2.4.0 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n","Requirement already satisfied: stack-data in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n","Requirement already satisfied: typing-extensions in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n","Requirement already satisfied: colorama in d:\\anaconda\\envs\\arten\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n","Requirement already satisfied: wcwidth in d:\\anaconda\\envs\\arten\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.13)\n","Requirement already satisfied: executing>=1.2.0 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n","Requirement already satisfied: asttokens>=2.1.0 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n","Requirement already satisfied: pure-eval in d:\\anaconda\\envs\\arten\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n","Requirement already satisfied: six>=1.12.0 in d:\\anaconda\\envs\\arten\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install ipywidgets"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-28T23:02:11.627105Z","iopub.status.busy":"2024-07-28T23:02:11.626755Z","iopub.status.idle":"2024-07-28T23:02:11.647398Z","shell.execute_reply":"2024-07-28T23:02:11.646781Z","shell.execute_reply.started":"2024-07-28T23:02:11.627075Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52179348eb80499cbe569d15f2779c15","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n","You can remove this warning by passing 'token=<use_auth_token>' instead.\n","  warnings.warn(\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32md:\\Project_ASR\\whisper-service\\Finetune\\notebookcbaec6e7aa.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project_ASR/whisper-service/Finetune/notebookcbaec6e7aa.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Load Indonesian and English datasets\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project_ASR/whisper-service/Finetune/notebookcbaec6e7aa.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m indonesian_data \u001b[39m=\u001b[39m DatasetDict()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Project_ASR/whisper-service/Finetune/notebookcbaec6e7aa.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m indonesian_data[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mmozilla-foundation/common_voice_17_0\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m\"\u001b[39;49m, split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain+validation\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_auth_token\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project_ASR/whisper-service/Finetune/notebookcbaec6e7aa.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m indonesian_data[\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39m\u001b[39mmozilla-foundation/common_voice_17_0\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m, split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, use_auth_token\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, trust_remote_code\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project_ASR/whisper-service/Finetune/notebookcbaec6e7aa.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m english_data \u001b[39m=\u001b[39m DatasetDict()\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\load.py:2587\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2582\u001b[0m verification_mode \u001b[39m=\u001b[39m VerificationMode(\n\u001b[0;32m   2583\u001b[0m     (verification_mode \u001b[39mor\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m save_infos \u001b[39melse\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS\n\u001b[0;32m   2584\u001b[0m )\n\u001b[0;32m   2586\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 2587\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[0;32m   2588\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[0;32m   2589\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   2590\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[0;32m   2591\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[0;32m   2592\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   2593\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m   2594\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m   2595\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m   2596\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   2597\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m   2598\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   2599\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code,\n\u001b[0;32m   2600\u001b[0m     _require_default_config_name\u001b[39m=\u001b[39;49mname \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   2601\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[0;32m   2602\u001b[0m )\n\u001b[0;32m   2604\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   2605\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\load.py:2259\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   2257\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   2258\u001b[0m     download_config\u001b[39m.\u001b[39mstorage_options\u001b[39m.\u001b[39mupdate(storage_options)\n\u001b[1;32m-> 2259\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[0;32m   2260\u001b[0m     path,\n\u001b[0;32m   2261\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   2262\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m   2263\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m   2264\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[0;32m   2265\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[0;32m   2266\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   2267\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code,\n\u001b[0;32m   2268\u001b[0m     _require_default_config_name\u001b[39m=\u001b[39;49m_require_default_config_name,\n\u001b[0;32m   2269\u001b[0m     _require_custom_configs\u001b[39m=\u001b[39;49m\u001b[39mbool\u001b[39;49m(config_kwargs),\n\u001b[0;32m   2270\u001b[0m )\n\u001b[0;32m   2271\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   2272\u001b[0m builder_kwargs \u001b[39m=\u001b[39m dataset_module\u001b[39m.\u001b[39mbuilder_kwargs\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\load.py:1876\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1874\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1875\u001b[0m     \u001b[39m# Otherwise we must use the dataset script if the user trusts it\u001b[39;00m\n\u001b[1;32m-> 1876\u001b[0m     \u001b[39mreturn\u001b[39;00m HubDatasetModuleFactoryWithScript(\n\u001b[0;32m   1877\u001b[0m         path,\n\u001b[0;32m   1878\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   1879\u001b[0m         download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m   1880\u001b[0m         download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m   1881\u001b[0m         dynamic_modules_path\u001b[39m=\u001b[39;49mdynamic_modules_path,\n\u001b[0;32m   1882\u001b[0m         trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code,\n\u001b[0;32m   1883\u001b[0m     )\u001b[39m.\u001b[39;49mget_module()\n\u001b[0;32m   1884\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1885\u001b[0m     \u001b[39mreturn\u001b[39;00m HubDatasetModuleFactoryWithoutScript(\n\u001b[0;32m   1886\u001b[0m         path,\n\u001b[0;32m   1887\u001b[0m         revision\u001b[39m=\u001b[39mrevision,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1891\u001b[0m         download_mode\u001b[39m=\u001b[39mdownload_mode,\n\u001b[0;32m   1892\u001b[0m     )\u001b[39m.\u001b[39mget_module()\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\load.py:1494\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithScript.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1487\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe repository for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m contains custom code which must be executed to correctly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1488\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mload the dataset. You can inspect the repository content at https://hf.co/datasets/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1491\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1492\u001b[0m     )\n\u001b[0;32m   1493\u001b[0m \u001b[39m# get script and other files\u001b[39;00m\n\u001b[1;32m-> 1494\u001b[0m local_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_loading_script()\n\u001b[0;32m   1495\u001b[0m dataset_infos_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_dataset_infos_file()\n\u001b[0;32m   1496\u001b[0m dataset_readme_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_dataset_readme_file()\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\load.py:1454\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithScript.download_loading_script\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[39mif\u001b[39;00m download_config\u001b[39m.\u001b[39mdownload_desc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1453\u001b[0m     download_config\u001b[39m.\u001b[39mdownload_desc \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDownloading builder script\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1454\u001b[0m \u001b[39mreturn\u001b[39;00m cached_path(file_path, download_config\u001b[39m=\u001b[39;49mdownload_config)\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\file_utils.py:201\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     url_or_filename \u001b[39m=\u001b[39m strip_protocol(url_or_filename)\n\u001b[0;32m    199\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m    200\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[0;32m    202\u001b[0m         url_or_filename,\n\u001b[0;32m    203\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    204\u001b[0m         force_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mforce_download,\n\u001b[0;32m    205\u001b[0m         proxies\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mproxies,\n\u001b[0;32m    206\u001b[0m         resume_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mresume_download,\n\u001b[0;32m    207\u001b[0m         user_agent\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muser_agent,\n\u001b[0;32m    208\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mlocal_files_only,\n\u001b[0;32m    209\u001b[0m         use_etag\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_etag,\n\u001b[0;32m    210\u001b[0m         max_retries\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    211\u001b[0m         token\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mtoken,\n\u001b[0;32m    212\u001b[0m         ignore_url_params\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mignore_url_params,\n\u001b[0;32m    213\u001b[0m         storage_options\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    214\u001b[0m         download_desc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mdownload_desc,\n\u001b[0;32m    215\u001b[0m         disable_tqdm\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mdisable_tqdm,\n\u001b[0;32m    216\u001b[0m     )\n\u001b[0;32m    217\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    218\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\file_utils.py:680\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, use_auth_token, ignore_url_params, storage_options, download_desc, disable_tqdm)\u001b[0m\n\u001b[0;32m    676\u001b[0m         fsspec_get(\n\u001b[0;32m    677\u001b[0m             url, temp_file, storage_options\u001b[39m=\u001b[39mstorage_options, desc\u001b[39m=\u001b[39mdownload_desc, disable_tqdm\u001b[39m=\u001b[39mdisable_tqdm\n\u001b[0;32m    678\u001b[0m         )\n\u001b[0;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         http_get(\n\u001b[0;32m    681\u001b[0m             url,\n\u001b[0;32m    682\u001b[0m             temp_file\u001b[39m=\u001b[39;49mtemp_file,\n\u001b[0;32m    683\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    684\u001b[0m             resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[0;32m    685\u001b[0m             headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    686\u001b[0m             cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[0;32m    687\u001b[0m             max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[0;32m    688\u001b[0m             desc\u001b[39m=\u001b[39;49mdownload_desc,\n\u001b[0;32m    689\u001b[0m             disable_tqdm\u001b[39m=\u001b[39;49mdisable_tqdm,\n\u001b[0;32m    690\u001b[0m         )\n\u001b[0;32m    692\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mcache_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    693\u001b[0m shutil\u001b[39m.\u001b[39mmove(temp_file\u001b[39m.\u001b[39mname, cache_path)\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\file_utils.py:424\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, cookies, timeout, max_retries, desc, disable_tqdm)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39mif\u001b[39;00m resume_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    423\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mRange\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbytes=\u001b[39m\u001b[39m{\u001b[39;00mresume_size\u001b[39m:\u001b[39;00m\u001b[39md\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 424\u001b[0m response \u001b[39m=\u001b[39m _request_with_retry(\n\u001b[0;32m    425\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    426\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    427\u001b[0m     stream\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    428\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    429\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    430\u001b[0m     cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[0;32m    431\u001b[0m     max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[0;32m    432\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    433\u001b[0m )\n\u001b[0;32m    434\u001b[0m \u001b[39mif\u001b[39;00m temp_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    435\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\file_utils.py:336\u001b[0m, in \u001b[0;36m_request_with_retry\u001b[1;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, **params)\u001b[0m\n\u001b[0;32m    334\u001b[0m tries \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    335\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod\u001b[39m.\u001b[39;49mupper(), url\u001b[39m=\u001b[39;49murl, timeout\u001b[39m=\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[0;32m    337\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39mexcept\u001b[39;00m (requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mConnectTimeout, requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mConnectionError) \u001b[39mas\u001b[39;00m err:\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\urllib3\\connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    463\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    466\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\http\\client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1346\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1347\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1349\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1350\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\http\\client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 316\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    318\u001b[0m         \u001b[39mbreak\u001b[39;00m\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\http\\client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 277\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    279\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1133\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# from datasets import load_dataset, DatasetDict, concatenate_datasets\n","\n","# # Load Indonesian and English datasets\n","# indonesian_data = DatasetDict()\n","# indonesian_data[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"id\", split=\"train+validation\", use_auth_token=True, trust_remote_code=True)\n","# indonesian_data[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"id\", split=\"test\", use_auth_token=True, trust_remote_code=True)\n","\n","# english_data = DatasetDict()\n","# english_data[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"en\", split=\"train+validation\", use_auth_token=True, trust_remote_code=True)\n","# english_data[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"en\", split=\"test\", use_auth_token=True, trust_remote_code=True)\n","\n","# # Combine datasets\n","# combined_data = DatasetDict()\n","# combined_data[\"train\"] = concatenate_datasets([indonesian_data[\"train\"], english_data[\"train\"]])\n","# combined_data[\"test\"] = concatenate_datasets([indonesian_data[\"test\"], english_data[\"test\"]])\n","\n","# print(combined_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor\n","\n","# # Use the existing tokenizer and processor\n","# feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n","# tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", task=\"transcribe\")\n","\n","# # Combine processor\n","# processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", task=\"transcribe\")\n","\n","# # Ensure the processor is aware of both languages\n","# processor.tokenizer.add_special_tokens({'additional_special_tokens': ['<|id|>', '<|en|>']})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from datasets import Audio\n","\n","# # Cast audio column to appropriate format\n","# combined_data = combined_data.cast_column(\"audio\", Audio(sampling_rate=16000))\n","\n","# def prepare_dataset(batch):\n","#     # Determine language and add special token\n","#     lang = 'id' if 'indonesian' in batch['sentence'] else 'en'\n","#     batch[\"sentence\"] = f\"<|{lang}|> \" + batch[\"sentence\"]\n","    \n","#     # load and resample audio data from 48 to 16kHz\n","#     audio = batch[\"audio\"]\n","#     batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n","#     batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n","#     return batch\n","\n","# combined_data = combined_data.map(prepare_dataset, remove_columns=combined_data.column_names[\"train\"], num_proc=4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from transformers import WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","# import torch\n","# from dataclasses import dataclass\n","# from typing import Any, Dict, List, Union\n","\n","# # Load the model\n","# model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n","\n","# # Adjust generation config for both languages\n","# model.generation_config.language = \"multilingual\"\n","# model.generation_config.task = \"transcribe\"\n","# model.generation_config.forced_decoder_ids = None\n","\n","# @dataclass\n","# class DataCollatorSpeechSeq2SeqWithPadding:\n","#     processor: Any\n","#     decoder_start_token_id: int\n","\n","#     def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","#         input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n","#         batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n","\n","#         label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n","#         labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n","#         labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n","\n","#         if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n","#             labels = labels[:, 1:]\n","\n","#         batch[\"labels\"] = labels\n","#         return batch\n","\n","# data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n","#     processor=processor,\n","#     decoder_start_token_id=model.config.decoder_start_token_id,\n","# )\n","\n","# import evaluate\n","\n","# metric = evaluate.load(\"wer\")\n","\n","# def compute_metrics(pred):\n","#     pred_ids = pred.predictions\n","#     label_ids = pred.label_ids\n","\n","#     label_ids[label_ids == -100] = tokenizer.pad_token_id\n","#     pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","#     label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n","#     wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n","#     return {\"wer\": wer}\n","\n","# training_args = Seq2SeqTrainingArguments(\n","#     output_dir=\"./whisper-small-multilingual\",\n","#     per_device_train_batch_size=8,\n","#     gradient_accumulation_steps=2,\n","#     learning_rate=3e-6,\n","#     warmup_steps=1000,\n","#     max_steps=4000,\n","#     gradient_checkpointing=True,\n","#     fp16=True,\n","#     evaluation_strategy=\"steps\",\n","#     per_device_eval_batch_size=8,\n","#     predict_with_generate=True,\n","#     generation_max_length=225,\n","#     save_steps=500,\n","#     eval_steps=500,\n","#     logging_steps=50,\n","#     report_to=[\"tensorboard\"],\n","#     load_best_model_at_end=True,\n","#     metric_for_best_model=\"wer\",\n","#     greater_is_better=False,\n","#     push_to_hub=True,\n","# )\n","\n","# trainer = Seq2SeqTrainer(\n","#     args=training_args,\n","#     model=model,\n","#     train_dataset=combined_data[\"train\"],\n","#     eval_dataset=combined_data[\"test\"],\n","#     data_collator=data_collator,\n","#     compute_metrics=compute_metrics,\n","#     tokenizer=processor.feature_extractor,\n","# )\n","\n","# trainer.train()\n","# kwargs = {\n","#     \"dataset_tags\": \"mozilla-foundation/common_voice_17_0\",\n","#     \"dataset\": \"Common Voice 17.0\",\n","#     \"dataset_args\": \"config: id+en, split: test\",\n","#     \"language\": \"multilingual\",\n","#     \"model_name\": \"Whisper Small Multilingual - tonimurfid\",\n","#     \"finetuned_from\": \"openai/whisper-small\",\n","#     \"tasks\": \"automatic-speech-recognition\",\n","# }\n","\n","# trainer.push_to_hub(**kwargs)\n","\n","# # Save the processor locally\n","# processor.save_pretrained(\"/kaggle/working/\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n","You can remove this warning by passing 'token=<use_auth_token>' instead.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"469e6b1f2d9449a1bef462f0bcf20163","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/8.19k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"980304f3443846b2b7133d0f96552e68","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/12.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3708968185514b4ca7ae7e34ccb48ce6","version_major":2,"version_minor":0},"text/plain":["Downloading extra modules:   0%|          | 0.00/3.92k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31ef810b5b674f57a3a7e203162c611c","version_major":2,"version_minor":0},"text/plain":["Downloading extra modules:   0%|          | 0.00/132k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"946edbbf92a340a7ae37d8ed8d491e4e","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/17.5k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d7d980476c940c1a0b4707de412ff91","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/170M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37592fe45a0847ecb4fa4e1526fc59b2","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/102M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"278a610b6bb44110bf3fd637ea1a5e48","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/110M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19ee9b02dd6b4dd9bdc43816b788c799","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/687M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"OSError","evalue":"[Errno 28] No space left on device","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\file_utils.py:659\u001b[0m, in \u001b[0;36mget_from_cache.<locals>.temp_file_manager\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(incomplete_path, mode) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m--> 659\u001b[0m     \u001b[39myield\u001b[39;00m f\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\file_utils.py:680\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, use_auth_token, ignore_url_params, storage_options, download_desc, disable_tqdm)\u001b[0m\n\u001b[0;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         http_get(\n\u001b[0;32m    681\u001b[0m             url,\n\u001b[0;32m    682\u001b[0m             temp_file\u001b[39m=\u001b[39;49mtemp_file,\n\u001b[0;32m    683\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    684\u001b[0m             resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[0;32m    685\u001b[0m             headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    686\u001b[0m             cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[0;32m    687\u001b[0m             max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[0;32m    688\u001b[0m             desc\u001b[39m=\u001b[39;49mdownload_desc,\n\u001b[0;32m    689\u001b[0m             disable_tqdm\u001b[39m=\u001b[39;49mdisable_tqdm,\n\u001b[0;32m    690\u001b[0m         )\n\u001b[0;32m    692\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mcache_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\file_utils.py:454\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, cookies, timeout, max_retries, desc, disable_tqdm)\u001b[0m\n\u001b[0;32m    453\u001b[0m progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n\u001b[1;32m--> 454\u001b[0m temp_file\u001b[39m.\u001b[39;49mwrite(chunk)\n","\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[1;32md:\\Project_ASR\\whisper-service\\Finetune\\notebookcbaec6e7aa.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project_ASR/whisper-service/Finetune/notebookcbaec6e7aa.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Load Indonesian and English datasets\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Project_ASR/whisper-service/Finetune/notebookcbaec6e7aa.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m indonesian_data \u001b[39m=\u001b[39m DatasetDict()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Project_ASR/whisper-service/Finetune/notebookcbaec6e7aa.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m indonesian_data[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mmozilla-foundation/common_voice_17_0\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m\"\u001b[39;49m, split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain+validation\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_auth_token\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Project_ASR/whisper-service/Finetune/notebookcbaec6e7aa.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m indonesian_data[\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39m\u001b[39mmozilla-foundation/common_voice_17_0\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m, split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, use_auth_token\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, trust_remote_code\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Project_ASR/whisper-service/Finetune/notebookcbaec6e7aa.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m english_data \u001b[39m=\u001b[39m DatasetDict()\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\load.py:2609\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2606\u001b[0m     \u001b[39mreturn\u001b[39;00m builder_instance\u001b[39m.\u001b[39mas_streaming_dataset(split\u001b[39m=\u001b[39msplit)\n\u001b[0;32m   2608\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[1;32m-> 2609\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[0;32m   2610\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m   2611\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m   2612\u001b[0m     verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[0;32m   2613\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[0;32m   2614\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   2615\u001b[0m )\n\u001b[0;32m   2617\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   2618\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[0;32m   2619\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[0;32m   2620\u001b[0m )\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\builder.py:1027\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m   1025\u001b[0m     \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1026\u001b[0m         prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n\u001b[1;32m-> 1027\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[0;32m   1028\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[0;32m   1029\u001b[0m         verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[0;32m   1030\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs,\n\u001b[0;32m   1031\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs,\n\u001b[0;32m   1032\u001b[0m     )\n\u001b[0;32m   1033\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\builder.py:1789\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[0;32m   1788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_download_and_prepare\u001b[39m(\u001b[39mself\u001b[39m, dl_manager, verification_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_splits_kwargs):\n\u001b[1;32m-> 1789\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[0;32m   1790\u001b[0m         dl_manager,\n\u001b[0;32m   1791\u001b[0m         verification_mode,\n\u001b[0;32m   1792\u001b[0m         check_duplicate_keys\u001b[39m=\u001b[39;49mverification_mode \u001b[39m==\u001b[39;49m VerificationMode\u001b[39m.\u001b[39;49mBASIC_CHECKS\n\u001b[0;32m   1793\u001b[0m         \u001b[39mor\u001b[39;49;00m verification_mode \u001b[39m==\u001b[39;49m VerificationMode\u001b[39m.\u001b[39;49mALL_CHECKS,\n\u001b[0;32m   1794\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_splits_kwargs,\n\u001b[0;32m   1795\u001b[0m     )\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\builder.py:1100\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m split_dict \u001b[39m=\u001b[39m SplitDict(dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name)\n\u001b[0;32m   1099\u001b[0m split_generators_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[1;32m-> 1100\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_split_generators(dl_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msplit_generators_kwargs)\n\u001b[0;32m   1102\u001b[0m \u001b[39m# Checksums verification\u001b[39;00m\n\u001b[0;32m   1103\u001b[0m \u001b[39mif\u001b[39;00m verification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS \u001b[39mand\u001b[39;00m dl_manager\u001b[39m.\u001b[39mrecord_checksums:\n","File \u001b[1;32m~\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\mozilla-foundation--common_voice_17_0\\9d10386a731ff6e6ed4ec973a4dc204a9820e8c842fbe388bdba0dd205ed5016\\common_voice_17_0.py:145\u001b[0m, in \u001b[0;36mCommonVoice._split_generators\u001b[1;34m(self, dl_manager)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m splits:\n\u001b[0;32m    142\u001b[0m     audio_urls[split] \u001b[39m=\u001b[39m [\n\u001b[0;32m    143\u001b[0m         _AUDIO_URL\u001b[39m.\u001b[39mformat(lang\u001b[39m=\u001b[39mlang, split\u001b[39m=\u001b[39msplit, shard_idx\u001b[39m=\u001b[39mi) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_shards[lang][split])\n\u001b[0;32m    144\u001b[0m     ]\n\u001b[1;32m--> 145\u001b[0m archive_paths \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39;49mdownload(audio_urls)\n\u001b[0;32m    146\u001b[0m local_extracted_archive_paths \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39mextract(archive_paths) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dl_manager\u001b[39m.\u001b[39mis_streaming \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m    148\u001b[0m meta_urls \u001b[39m=\u001b[39m {split: _TRANSCRIPT_URL\u001b[39m.\u001b[39mformat(lang\u001b[39m=\u001b[39mlang, split\u001b[39m=\u001b[39msplit) \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m splits}\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\download\\download_manager.py:257\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    255\u001b[0m start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m    256\u001b[0m \u001b[39mwith\u001b[39;00m stack_multiprocessing_download_progress_bars():\n\u001b[1;32m--> 257\u001b[0m     downloaded_path_or_paths \u001b[39m=\u001b[39m map_nested(\n\u001b[0;32m    258\u001b[0m         download_func,\n\u001b[0;32m    259\u001b[0m         url_or_urls,\n\u001b[0;32m    260\u001b[0m         map_tuple\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    261\u001b[0m         num_proc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mnum_proc,\n\u001b[0;32m    262\u001b[0m         desc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDownloading data files\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    263\u001b[0m         batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    264\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m    265\u001b[0m     )\n\u001b[0;32m    266\u001b[0m duration \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m start_time\n\u001b[0;32m    267\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading took \u001b[39m\u001b[39m{\u001b[39;00mduration\u001b[39m.\u001b[39mtotal_seconds()\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39m60\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m min\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\py_utils.py:511\u001b[0m, in \u001b[0;36mmap_nested\u001b[1;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[0;32m    509\u001b[0m         batch_size \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mlen\u001b[39m(iterable) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m num_proc \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(iterable) \u001b[39m%\u001b[39m num_proc \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[0;32m    510\u001b[0m     iterable \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[1;32m--> 511\u001b[0m mapped \u001b[39m=\u001b[39m [\n\u001b[0;32m    512\u001b[0m     _single_map_nested((function, obj, batched, batch_size, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    513\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m hf_tqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[0;32m    514\u001b[0m ]\n\u001b[0;32m    515\u001b[0m \u001b[39mif\u001b[39;00m batched:\n\u001b[0;32m    516\u001b[0m     mapped \u001b[39m=\u001b[39m [mapped_item \u001b[39mfor\u001b[39;00m mapped_batch \u001b[39min\u001b[39;00m mapped \u001b[39mfor\u001b[39;00m mapped_item \u001b[39min\u001b[39;00m mapped_batch]\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\py_utils.py:512\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    509\u001b[0m         batch_size \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mlen\u001b[39m(iterable) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m num_proc \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(iterable) \u001b[39m%\u001b[39m num_proc \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[0;32m    510\u001b[0m     iterable \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[0;32m    511\u001b[0m mapped \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 512\u001b[0m     _single_map_nested((function, obj, batched, batch_size, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m))\n\u001b[0;32m    513\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m hf_tqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[0;32m    514\u001b[0m ]\n\u001b[0;32m    515\u001b[0m \u001b[39mif\u001b[39;00m batched:\n\u001b[0;32m    516\u001b[0m     mapped \u001b[39m=\u001b[39m [mapped_item \u001b[39mfor\u001b[39;00m mapped_batch \u001b[39min\u001b[39;00m mapped \u001b[39mfor\u001b[39;00m mapped_item \u001b[39min\u001b[39;00m mapped_batch]\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\py_utils.py:399\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m    396\u001b[0m         k: _single_map_nested((function, v, batched, batch_size, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m pbar\n\u001b[0;32m    397\u001b[0m     }\n\u001b[0;32m    398\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     mapped \u001b[39m=\u001b[39m [_single_map_nested((function, v, batched, batch_size, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m pbar]\n\u001b[0;32m    400\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    401\u001b[0m         \u001b[39mreturn\u001b[39;00m mapped\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\py_utils.py:399\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m    396\u001b[0m         k: _single_map_nested((function, v, batched, batch_size, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m pbar\n\u001b[0;32m    397\u001b[0m     }\n\u001b[0;32m    398\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     mapped \u001b[39m=\u001b[39m [_single_map_nested((function, v, batched, batch_size, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m pbar]\n\u001b[0;32m    400\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    401\u001b[0m         \u001b[39mreturn\u001b[39;00m mapped\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\py_utils.py:380\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[0;32m    374\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    375\u001b[0m     batched\n\u001b[0;32m    376\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m)\n\u001b[0;32m    377\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types)\n\u001b[0;32m    378\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(v, (\u001b[39mdict\u001b[39m, types)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m data_struct)\n\u001b[0;32m    379\u001b[0m ):\n\u001b[1;32m--> 380\u001b[0m     \u001b[39mreturn\u001b[39;00m [mapped_item \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[39mfor\u001b[39;00m mapped_item \u001b[39min\u001b[39;00m function(batch)]\n\u001b[0;32m    382\u001b[0m \u001b[39m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m logging\u001b[39m.\u001b[39mget_verbosity() \u001b[39m<\u001b[39m logging\u001b[39m.\u001b[39mWARNING:\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\py_utils.py:380\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[0;32m    374\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    375\u001b[0m     batched\n\u001b[0;32m    376\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m)\n\u001b[0;32m    377\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types)\n\u001b[0;32m    378\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(v, (\u001b[39mdict\u001b[39m, types)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m data_struct)\n\u001b[0;32m    379\u001b[0m ):\n\u001b[1;32m--> 380\u001b[0m     \u001b[39mreturn\u001b[39;00m [mapped_item \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[39mfor\u001b[39;00m mapped_item \u001b[39min\u001b[39;00m function(batch)]\n\u001b[0;32m    382\u001b[0m \u001b[39m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m logging\u001b[39m.\u001b[39mget_verbosity() \u001b[39m<\u001b[39m logging\u001b[39m.\u001b[39mWARNING:\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\download\\download_manager.py:313\u001b[0m, in \u001b[0;36mDownloadManager._download_batched\u001b[1;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m thread_map(\n\u001b[0;32m    301\u001b[0m         download_func,\n\u001b[0;32m    302\u001b[0m         url_or_filenames,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    310\u001b[0m         tqdm_class\u001b[39m=\u001b[39mtqdm,\n\u001b[0;32m    311\u001b[0m     )\n\u001b[0;32m    312\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m    314\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_single(url_or_filename, download_config\u001b[39m=\u001b[39mdownload_config)\n\u001b[0;32m    315\u001b[0m         \u001b[39mfor\u001b[39;00m url_or_filename \u001b[39min\u001b[39;00m url_or_filenames\n\u001b[0;32m    316\u001b[0m     ]\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\download\\download_manager.py:314\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m thread_map(\n\u001b[0;32m    301\u001b[0m         download_func,\n\u001b[0;32m    302\u001b[0m         url_or_filenames,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    310\u001b[0m         tqdm_class\u001b[39m=\u001b[39mtqdm,\n\u001b[0;32m    311\u001b[0m     )\n\u001b[0;32m    312\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m--> 314\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_single(url_or_filename, download_config\u001b[39m=\u001b[39;49mdownload_config)\n\u001b[0;32m    315\u001b[0m         \u001b[39mfor\u001b[39;00m url_or_filename \u001b[39min\u001b[39;00m url_or_filenames\n\u001b[0;32m    316\u001b[0m     ]\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\download\\download_manager.py:323\u001b[0m, in \u001b[0;36mDownloadManager._download_single\u001b[1;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[0;32m    321\u001b[0m     \u001b[39m# append the relative path to the base_path\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     url_or_filename \u001b[39m=\u001b[39m url_or_path_join(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_path, url_or_filename)\n\u001b[1;32m--> 323\u001b[0m out \u001b[39m=\u001b[39m cached_path(url_or_filename, download_config\u001b[39m=\u001b[39;49mdownload_config)\n\u001b[0;32m    324\u001b[0m out \u001b[39m=\u001b[39m tracked_str(out)\n\u001b[0;32m    325\u001b[0m out\u001b[39m.\u001b[39mset_origin(url_or_filename)\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\file_utils.py:201\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     url_or_filename \u001b[39m=\u001b[39m strip_protocol(url_or_filename)\n\u001b[0;32m    199\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m    200\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[0;32m    202\u001b[0m         url_or_filename,\n\u001b[0;32m    203\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    204\u001b[0m         force_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mforce_download,\n\u001b[0;32m    205\u001b[0m         proxies\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mproxies,\n\u001b[0;32m    206\u001b[0m         resume_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mresume_download,\n\u001b[0;32m    207\u001b[0m         user_agent\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muser_agent,\n\u001b[0;32m    208\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mlocal_files_only,\n\u001b[0;32m    209\u001b[0m         use_etag\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_etag,\n\u001b[0;32m    210\u001b[0m         max_retries\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    211\u001b[0m         token\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mtoken,\n\u001b[0;32m    212\u001b[0m         ignore_url_params\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mignore_url_params,\n\u001b[0;32m    213\u001b[0m         storage_options\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    214\u001b[0m         download_desc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mdownload_desc,\n\u001b[0;32m    215\u001b[0m         disable_tqdm\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mdisable_tqdm,\n\u001b[0;32m    216\u001b[0m     )\n\u001b[0;32m    217\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    218\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\file_utils.py:680\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, use_auth_token, ignore_url_params, storage_options, download_desc, disable_tqdm)\u001b[0m\n\u001b[0;32m    676\u001b[0m         fsspec_get(\n\u001b[0;32m    677\u001b[0m             url, temp_file, storage_options\u001b[39m=\u001b[39mstorage_options, desc\u001b[39m=\u001b[39mdownload_desc, disable_tqdm\u001b[39m=\u001b[39mdisable_tqdm\n\u001b[0;32m    678\u001b[0m         )\n\u001b[0;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         http_get(\n\u001b[0;32m    681\u001b[0m             url,\n\u001b[0;32m    682\u001b[0m             temp_file\u001b[39m=\u001b[39mtemp_file,\n\u001b[0;32m    683\u001b[0m             proxies\u001b[39m=\u001b[39mproxies,\n\u001b[0;32m    684\u001b[0m             resume_size\u001b[39m=\u001b[39mresume_size,\n\u001b[0;32m    685\u001b[0m             headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    686\u001b[0m             cookies\u001b[39m=\u001b[39mcookies,\n\u001b[0;32m    687\u001b[0m             max_retries\u001b[39m=\u001b[39mmax_retries,\n\u001b[0;32m    688\u001b[0m             desc\u001b[39m=\u001b[39mdownload_desc,\n\u001b[0;32m    689\u001b[0m             disable_tqdm\u001b[39m=\u001b[39mdisable_tqdm,\n\u001b[0;32m    690\u001b[0m         )\n\u001b[0;32m    692\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mcache_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    693\u001b[0m shutil\u001b[39m.\u001b[39mmove(temp_file\u001b[39m.\u001b[39mname, cache_path)\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\contextlib.py:131\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    129\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m()\n\u001b[0;32m    130\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(\u001b[39mtype\u001b[39;49m, value, traceback)\n\u001b[0;32m    132\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    133\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m value\n","File \u001b[1;32md:\\Anaconda\\envs\\Arten\\lib\\site-packages\\datasets\\utils\\file_utils.py:659\u001b[0m, in \u001b[0;36mget_from_cache.<locals>.temp_file_manager\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[39m@contextmanager\u001b[39m\n\u001b[0;32m    657\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtemp_file_manager\u001b[39m(mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mw+b\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    658\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(incomplete_path, mode) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m--> 659\u001b[0m         \u001b[39myield\u001b[39;00m f\n","\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"]}],"source":["from datasets import load_dataset, DatasetDict, concatenate_datasets, Audio\n","from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","import torch\n","from dataclasses import dataclass\n","from typing import Any, Dict, List, Union\n","import evaluate\n","\n","# Load Indonesian and English datasets\n","indonesian_data = DatasetDict()\n","indonesian_data[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"id\", split=\"train+validation\", use_auth_token=True, trust_remote_code=True)\n","indonesian_data[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"id\", split=\"test\", use_auth_token=True, trust_remote_code=True)\n","\n","english_data = DatasetDict()\n","english_data[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"en\", split=\"train+validation\", use_auth_token=True, trust_remote_code=True)\n","english_data[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"en\", split=\"test\", use_auth_token=True, trust_remote_code=True)\n","\n","# Combine datasets\n","combined_data = DatasetDict()\n","combined_data[\"train\"] = concatenate_datasets([indonesian_data[\"train\"], english_data[\"train\"]])\n","combined_data[\"test\"] = concatenate_datasets([indonesian_data[\"test\"], english_data[\"test\"]])\n","\n","print(combined_data)\n","\n","# Initialize feature extractor, tokenizer, and processor\n","feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n","tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", task=\"transcribe\")\n","processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", task=\"transcribe\")\n","\n","# Ensure the processor is aware of both languages\n","processor.tokenizer.add_special_tokens({'additional_special_tokens': ['<|id|>', '<|en|>']})\n","\n","# Cast audio column to appropriate format\n","combined_data = combined_data.cast_column(\"audio\", Audio(sampling_rate=16000))\n","\n","def prepare_dataset(batch):\n","    lang = 'id' if 'indonesian' in batch['sentence'] else 'en'\n","    batch[\"sentence\"] = f\"<|{lang}|> \" + batch[\"sentence\"]\n","    audio = batch[\"audio\"]\n","    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n","    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n","    return batch\n","\n","combined_data = combined_data.map(prepare_dataset, remove_columns=combined_data.column_names[\"train\"], num_proc=4)\n","\n","# Load the model and move to CUDA\n","model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n","model.cuda()  # Move model to GPU\n","\n","# Adjust generation config for both languages\n","model.generation_config.language = \"multilingual\"\n","model.generation_config.task = \"transcribe\"\n","model.generation_config.forced_decoder_ids = None\n","\n","@dataclass\n","class DataCollatorSpeechSeq2SeqWithPadding:\n","    processor: Any\n","    decoder_start_token_id: int\n","\n","    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n","        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n","        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n","        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n","        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n","        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n","            labels = labels[:, 1:]\n","        batch[\"labels\"] = labels\n","        return batch\n","\n","data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n","    processor=processor,\n","    decoder_start_token_id=model.config.decoder_start_token_id,\n",")\n","\n","metric = evaluate.load(\"wer\")\n","\n","def compute_metrics(pred):\n","    pred_ids = pred.predictions\n","    label_ids = pred.label_ids\n","    label_ids[label_ids == -100] = tokenizer.pad_token_id\n","    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n","    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n","    return {\"wer\": wer}\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./whisper-small-multilingual\",\n","    per_device_train_batch_size=8,\n","    gradient_accumulation_steps=2,\n","    learning_rate=1e-6,\n","    warmup_steps=1000,\n","    max_steps=4000,\n","    gradient_checkpointing=True,\n","    fp16=True,\n","    evaluation_strategy=\"steps\",\n","    per_device_eval_batch_size=8,\n","    predict_with_generate=True,\n","    generation_max_length=225,\n","    save_steps=500,\n","    eval_steps=500,\n","    logging_steps=50,\n","    report_to=[\"tensorboard\"],\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"wer\",\n","    greater_is_better=False,\n","    push_to_hub=True,\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    args=training_args,\n","    model=model,\n","    train_dataset=combined_data[\"train\"],\n","    eval_dataset=combined_data[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=processor.feature_extractor,\n",")\n","\n","trainer.train()\n","\n","kwargs = {\n","    \"dataset_tags\": \"mozilla-foundation/common_voice_17_0\",\n","    \"dataset\": \"Common Voice 17.0\",\n","    \"dataset_args\": \"config: id+en, split: test\",\n","    \"language\": \"multilingual\",\n","    \"model_name\": \"Whisper Small Multilingual - tonimurfid\",\n","    \"finetuned_from\": \"openai/whisper-small\",\n","    \"tasks\": \"automatic-speech-recognition\",\n","}\n","\n","trainer.push_to_hub(**kwargs)\n","processor.save_pretrained(\"/kaggle/working/\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":4}
